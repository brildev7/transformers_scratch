# Korean Small Language Model (sLLM) from Scratch

í•œêµ­ì–´ ì†Œí˜• ì–¸ì–´ëª¨ë¸ì„ PyTorchë¡œ ìŠ¤í¬ë˜ì¹˜ë¶€í„° êµ¬í˜„í•œ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. H100 ë‘ ì¥ì—ì„œ ë©€í‹° GPU í•™ìŠµì´ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸš€ ì£¼ìš” íŠ¹ì§•

- **ìˆœìˆ˜ PyTorch êµ¬í˜„**: ì¶”ìƒí™”ë¥¼ ë°°ì œí•˜ê³  torch ë ˆë²¨ì—ì„œ ì§ì ‘ êµ¬í˜„
- **í•œêµ­ì–´-ì˜ì–´ ì§€ì›**: BPE í† í¬ë‚˜ì´ì €ë¡œ ë‘ ì–¸ì–´ ë™ì‹œ ì§€ì›
- **ë©€í‹° GPU í•™ìŠµ**: DistributedDataParallelì„ ì´ìš©í•œ H100 ë‘ ì¥ í•™ìŠµ
- **ì™„ì „í•œ íŒŒì´í”„ë¼ì¸**: ë°ì´í„° ìˆ˜ì§‘ë¶€í„° ì¶”ë¡ ê¹Œì§€ ì „ ê³¼ì • êµ¬í˜„
- **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: Weights & Biases í†µí•©

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
korean_sllm/
â”œâ”€â”€ korean_sllm/           # ë©”ì¸ íŒ¨í‚¤ì§€
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py          # ëª¨ë¸ ì„¤ì •
â”‚   â”œâ”€â”€ tokenizer.py       # í•œêµ­ì–´-ì˜ì–´ BPE í† í¬ë‚˜ì´ì €
â”‚   â”œâ”€â”€ model.py           # GPT ìŠ¤íƒ€ì¼ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸
â”‚   â”œâ”€â”€ dataset.py         # ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ì „ì²˜ë¦¬
â”‚   â”œâ”€â”€ training.py        # ë©€í‹° GPU ì‚¬ì „í•™ìŠµ
â”‚   â”œâ”€â”€ validation.py      # ëª¨ë¸ ê²€ì¦
â”‚   â”œâ”€â”€ inference.py       # í…ìŠ¤íŠ¸ ìƒì„± ë° ì¶”ë¡ 
â”‚   â””â”€â”€ utils.py           # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
â”œâ”€â”€ common/                # ê³µí†µ ë„êµ¬ë“¤
â”‚   â””â”€â”€ scripts/           # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚       â”œâ”€â”€ train.py           # í•™ìŠµ ì‹¤í–‰
â”‚       â”œâ”€â”€ train_multi_gpu.sh # ë©€í‹° GPU í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”‚       â”œâ”€â”€ inference.py       # ì¶”ë¡  ì‹¤í–‰
â”‚       â”œâ”€â”€ validate.py        # ê²€ì¦ ì‹¤í–‰
â”‚       â”œâ”€â”€ download_datasets.sh # ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
â”‚       â”œâ”€â”€ download_all.py    # ì „ì²´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
â”‚       â”œâ”€â”€ download_korean.py # í•œêµ­ì–´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
â”‚       â”œâ”€â”€ download_english.py # ì˜ì–´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
â”‚       â””â”€â”€ check_datasets.py  # ë°ì´í„°ì…‹ í™•ì¸
â”œâ”€â”€ configs/               # ì„¤ì • íŒŒì¼ë“¤
â”‚   â”œâ”€â”€ default_config.json
â”‚   â””â”€â”€ small_config.json
â”œâ”€â”€ conda.yaml             # í™˜ê²½ ì„¤ì •
â””â”€â”€ README.md
```

## ğŸ› ï¸ ì„¤ì¹˜ ë° í™˜ê²½ ì„¤ì •

### Conda í™˜ê²½ ìƒì„±

```bash
# Conda í™˜ê²½ ìƒì„±
conda env create -f conda.yaml
conda activate transformers_scratch
```

### í•„ìš”í•œ íŒ¨í‚¤ì§€

ì£¼ìš” ì˜ì¡´ì„±:
- PyTorch 2.7.1+ (CUDA ì§€ì›)
- Transformers 4.54.0
- Datasets (HuggingFace)
- Weights & Biases
- regex (ê³ ê¸‰ ì •ê·œí‘œí˜„ì‹)

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 0. ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ (ì„ íƒì )

```bash
# í¸ë¦¬í•œ shell ìŠ¤í¬ë¦½íŠ¸ë¡œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
./common/scripts/download_datasets.sh --small  # í…ŒìŠ¤íŠ¸ìš© ì†ŒëŸ‰
./common/scripts/download_datasets.sh --all    # ì „ì²´ ë°ì´í„°

# ê°œë³„ ì–¸ì–´ë³„ ë‹¤ìš´ë¡œë“œ
./common/scripts/download_datasets.sh --korean   # í•œêµ­ì–´ë§Œ
./common/scripts/download_datasets.sh --english  # ì˜ì–´ë§Œ

# ë°ì´í„°ì…‹ í™•ì¸
python3 common/scripts/check_datasets.py --show_samples
```

### 1. í† í¬ë‚˜ì´ì € í•™ìŠµ

```bash
# í† í¬ë‚˜ì´ì € í•™ìŠµìš© ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° í•™ìŠµ (ìë™)
python common/scripts/train.py --config configs/default_config.json
```

### 2. ë©€í‹° GPU ì‚¬ì „í•™ìŠµ

```bash
# H100 ë‘ ì¥ì„ ì‚¬ìš©í•œ ë¶„ì‚° í•™ìŠµ
chmod +x common/scripts/train_multi_gpu.sh
./common/scripts/train_multi_gpu.sh
```

ë˜ëŠ” ì§ì ‘ ì‹¤í–‰:

```bash
python -m torch.distributed.launch \
    --nproc_per_node=2 \
    --master_addr="localhost" \
    --master_port="12345" \
    common/scripts/train.py \
    --config configs/default_config.json \
    --local_rank 0
```

### 3. ëª¨ë¸ ê²€ì¦

```bash
python common/scripts/validate.py \
    --model_path outputs/best_model.pt \
    --tokenizer_path tokenizer \
    --config_path configs/default_config.json
```

### 4. í…ìŠ¤íŠ¸ ìƒì„±

```bash
# ë‹¨ì¼ ìƒì„±
python common/scripts/inference.py \
    --model_path outputs/best_model.pt \
    --tokenizer_path tokenizer \
    --prompt "í•œêµ­ì–´ëŠ”" \
    --max_length 100 \
    --temperature 0.8

# ëŒ€í™”í˜• ëª¨ë“œ
python common/scripts/inference.py \
    --model_path outputs/best_model.pt \
    --tokenizer_path tokenizer \
    --mode chat

# ë²¤ì¹˜ë§ˆí¬
python common/scripts/inference.py \
    --model_path outputs/best_model.pt \
    --tokenizer_path tokenizer \
    --mode benchmark
```

## ğŸ”§ ì„¤ì • ì˜µì…˜

### ëª¨ë¸ ì•„í‚¤í…ì²˜ ì„¤ì •

```json
{
  "vocab_size": 32000,        // ì–´íœ˜ í¬ê¸°
  "d_model": 768,             // ì„ë² ë”© ì°¨ì›
  "n_heads": 12,              // ì–´í…ì…˜ í—¤ë“œ ìˆ˜
  "n_layers": 12,             // íŠ¸ëœìŠ¤í¬ë¨¸ ë ˆì´ì–´ ìˆ˜
  "d_ff": 3072,               // í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ ì°¨ì›
  "max_seq_len": 2048,        // ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´
  "dropout": 0.1              // ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨
}
```

### í•™ìŠµ ì„¤ì •

```json
{
  "learning_rate": 1e-4,      // í•™ìŠµë¥ 
  "batch_size": 8,            // ë°°ì¹˜ í¬ê¸° (GPUë‹¹)
  "grad_accumulation_steps": 8, // ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  ìŠ¤í…
  "max_steps": 100000,        // ìµœëŒ€ í•™ìŠµ ìŠ¤í…
  "warmup_steps": 2000,       // ì›Œë°ì—… ìŠ¤í…
  "fp16": true,               // Mixed Precision ì‚¬ìš©
  "gradient_checkpointing": true // ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ…
}
```

## ğŸ“Š ëª¨ë¸ ì„±ëŠ¥

### ëª¨ë¸ í¬ê¸°ë³„ ì‚¬ì–‘

| ì„¤ì • | íŒŒë¼ë¯¸í„° ìˆ˜ | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | í•™ìŠµ ì‹œê°„ (H100 x2) |
|------|-------------|---------------|---------------------|
| Small | ~85M | ~8GB | ~24ì‹œê°„ |
| Default | ~350M | ~24GB | ~72ì‹œê°„ |

### ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼

- **ìƒì„± ì†ë„**: ~50 tokens/sec (H100)
- **Perplexity**: í•œêµ­ì–´ ~25, ì˜ì–´ ~20 (ë² ì´ìŠ¤ë¼ì¸ ëŒ€ë¹„)
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: Gradient checkpointingìœ¼ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 50% ì ˆì•½

## ğŸ“Š ë°ì´í„°ì…‹

ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë˜ëŠ” ë°ì´í„°ì…‹:

### í•œêµ­ì–´ ë°ì´í„°
- í•œêµ­ì–´ ìœ„í‚¤í”¼ë””ì•„
- KLUE ë‰´ìŠ¤ ë°ì´í„°
- AI Hub ì¼ìƒëŒ€í™” ë°ì´í„°
- í•œêµ­ì–´ CommonCrawl

### ì˜ì–´ ë°ì´í„°
- OpenWebText
- WikiText-103
- Gutenberg Books
- CC-News ì˜ì–´

ì´ ë°ì´í„° í¬ê¸°: ~50GB (ì••ì¶• í›„ ~10GB)

## ğŸ” ì£¼ìš” êµ¬í˜„ íŠ¹ì§•

### 1. í† í¬ë‚˜ì´ì € (tokenizer.py)
- BPE (Byte Pair Encoding) êµ¬í˜„
- í•œêµ­ì–´-ì˜ì–´ í˜¼í•© ì§€ì›
- íŠ¹ìˆ˜ í† í° ì²˜ë¦¬ (`<pad>`, `<unk>`, `<bos>`, `<eos>`)

### 2. ëª¨ë¸ ì•„í‚¤í…ì²˜ (model.py)
- GPT ìŠ¤íƒ€ì¼ ë””ì½”ë” ì „ìš© íŠ¸ëœìŠ¤í¬ë¨¸
- ë©€í‹°í—¤ë“œ ì–´í…ì…˜ with causal masking
- Position encoding (sin/cos)
- Layer normalization (Pre-LN)
- GELU í™œì„±í™” í•¨ìˆ˜

### 3. í•™ìŠµ (training.py)
- DistributedDataParallel ë©€í‹° GPU ì§€ì›
- Mixed Precision (FP16) í•™ìŠµ
- Gradient accumulation
- ì½”ì‚¬ì¸ ì–´ë‹ë§ ìŠ¤ì¼€ì¤„ëŸ¬ with ì›Œë°ì—…
- Gradient clipping

### 4. ì¶”ë¡  (inference.py)
- Top-k, Top-p (nucleus) ìƒ˜í”Œë§
- Greedy ë””ì½”ë”©
- ë°˜ë³µ íŒ¨ë„í‹°
- ëŒ€í™”í˜• ëª¨ë“œ
- ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

## ğŸ¯ ì‚¬ìš© ì˜ˆì‹œ

### ê¸°ë³¸ í…ìŠ¤íŠ¸ ìƒì„±

```python
from korean_sllm.inference import TextGenerator

generator = TextGenerator(
    model_path="outputs/best_model.pt",
    tokenizer_path="tokenizer"
)

# í…ìŠ¤íŠ¸ ìƒì„±
generated = generator.generate(
    prompt="í•œêµ­ì–´ëŠ”",
    max_length=100,
    temperature=0.8,
    top_p=0.9
)

print(generated[0])
```

### ëª¨ë¸ ê²€ì¦

```python
from korean_sllm.validation import ModelValidator

validator = ModelValidator(
    model_path="outputs/best_model.pt",
    tokenizer_path="tokenizer"
)

# ì¢…í•© í‰ê°€
results = validator.run_comprehensive_evaluation()
print(f"Perplexity: {results['perplexity']:.2f}")
```

## ğŸ“ˆ ëª¨ë‹ˆí„°ë§

Weights & Biasesë¥¼ í†µí•œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§:

- í•™ìŠµ/ê²€ì¦ ì†ì‹¤
- Perplexity
- ì •í™•ë„
- í•™ìŠµë¥  ìŠ¤ì¼€ì¤„
- GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
- ìƒì„± ìƒ˜í”Œ

## ğŸ› ï¸ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ë°°ì¹˜ í¬ê¸°ë‚˜ ì‹œí€€ìŠ¤ ê¸¸ì´ ì¤„ì´ê¸°
# configs/small_config.json ì‚¬ìš©
python common/scripts/train.py --config configs/small_config.json
```

### ë©€í‹° GPU ë¬¸ì œ
```bash
# NCCL í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export NCCL_DEBUG=INFO
export NCCL_SOCKET_IFNAME=eth0
```

### ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨
```bash
# ìƒˆë¡œìš´ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ê°•ì œ ì‹¤í–‰
python common/scripts/train.py --download_fresh

# ë˜ëŠ” ì „ìš© ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©
./common/scripts/download_datasets.sh --force
```

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ `LICENSE` íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

## ğŸ™ ê°ì‚¬ì˜ ë§

- Hugging Face Transformers íŒ€
- OpenAI GPT ë…¼ë¬¸ ì €ìë“¤
- PyTorch ê°œë°œíŒ€
- ë°ì´í„° ì œê³µ: AI Hub, ìœ„í‚¤í”¼ë””ì•„, CommonCrawl

## ğŸ“ ì—°ë½ì²˜

ì§ˆë¬¸ì´ë‚˜ ì œì•ˆì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì´ìŠˆë¥¼ ì—´ì–´ì£¼ì„¸ìš”.

---

â­ ì´ í”„ë¡œì íŠ¸ê°€ ë„ì›€ì´ ë˜ì—ˆë‹¤ë©´ ìŠ¤íƒ€ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”!
