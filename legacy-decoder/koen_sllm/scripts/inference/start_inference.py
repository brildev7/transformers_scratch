#!/usr/bin/env python3
"""
í•œêµ­ì–´ ì†Œí˜• ì–¸ì–´ëª¨ë¸ ì¶”ë¡  ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸

ê°„ë‹¨í•œ ëª…ë ¹ì–´ë¡œ ì¶”ë¡ ì„ ì‹œì‘í•  ìˆ˜ ìˆëŠ” ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.
"""

import sys
import os
import argparse
from pathlib import Path


def resolve_model_path(model_dir):
    """ëª¨ë¸ ê²½ë¡œ í•´ì„ ë° í•´ê²°"""
    # ì ˆëŒ€ ê²½ë¡œì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
    if os.path.isabs(model_dir):
        return model_dir
    
    # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° ì—¬ëŸ¬ ìœ„ì¹˜ì—ì„œ ì°¾ê¸°
    possible_paths = [
        model_dir,  # í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€
        f"../../../../{model_dir}",  # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€
        f"../../../../../{model_dir}",  # ìƒìœ„ ë””ë ‰í† ë¦¬ ê¸°ì¤€
    ]
    
    # outputsë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš° í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œë„ ì°¾ê¸°
    if model_dir.startswith("./outputs/") or model_dir.startswith("outputs/"):
        checkpoint_name = model_dir.split("/")[-1]
        possible_paths.extend([
            f"../../../../outputs/{checkpoint_name}",
            f"../../../../../outputs/{checkpoint_name}",
        ])
    
    for path in possible_paths:
        if os.path.exists(path):
            return os.path.abspath(path)
    
    return model_dir  # ì°¾ì§€ ëª»í•˜ë©´ ì›ë˜ ê²½ë¡œ ë°˜í™˜


def validate_model_directory(model_dir):
    """ëª¨ë¸ ë””ë ‰í† ë¦¬ ìœ íš¨ì„± ê²€ì‚¬"""
    # ê²½ë¡œ í•´ì„
    resolved_path = resolve_model_path(model_dir)
    model_path = Path(resolved_path)
    
    if not model_path.exists():
        print(f"âŒ ëª¨ë¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_dir}")
        print(f"   (í•´ì„ëœ ê²½ë¡œ: {resolved_path})")
        return False
    
    # í•„ìš”í•œ íŒŒì¼ë“¤ í™•ì¸
    required_files = ["pytorch_model.bin", "config.json"]
    missing_files = []
    
    for file_name in required_files:
        if not (model_path / file_name).exists():
            missing_files.append(file_name)
    
    if missing_files:
        print(f"âŒ í•„ìˆ˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_files)}")
        return False
    
    print(f"âœ… ëª¨ë¸ ë””ë ‰í† ë¦¬ í™•ì¸: {resolved_path}")
    return True


def find_checkpoints(base_dirs=None):
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°"""
    if base_dirs is None:
        base_dirs = [
            "./outputs",  # í˜„ì¬ ë””ë ‰í† ë¦¬
            "../../../../outputs",  # í”„ë¡œì íŠ¸ ë£¨íŠ¸
            "../../../../../outputs",  # ìƒìœ„ ë””ë ‰í† ë¦¬
        ]
    
    checkpoints = []
    
    for base_dir in base_dirs:
        base_path = Path(base_dir)
        if base_path.exists():
            for item in base_path.iterdir():
                if item.is_dir() and item.name.startswith("checkpoint-"):
                    abs_path = str(item.resolve())
                    if abs_path not in checkpoints:
                        # ê°„ë‹¨í•œ ìœ íš¨ì„± ê²€ì‚¬ (íŒŒì¼ ì¡´ì¬ë§Œ í™•ì¸)
                        if (item / "pytorch_model.bin").exists() and (item / "config.json").exists():
                            checkpoints.append(abs_path)
    
    return sorted(checkpoints)


def list_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¶œë ¥"""
    print("ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸:")
    print("-" * 50)
    
    checkpoints = find_checkpoints()
    if not checkpoints:
        print("ì‚¬ìš© ê°€ëŠ¥í•œ ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("./outputs/ ë””ë ‰í† ë¦¬ì— ì²´í¬í¬ì¸íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return False
    
    for i, cp in enumerate(checkpoints, 1):
        print(f"{i:2d}. {cp}")
    
    return True


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="í•œêµ­ì–´ ì†Œí˜• ì–¸ì–´ëª¨ë¸ ì¶”ë¡  ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python start_inference.py                                   # ì²´í¬í¬ì¸íŠ¸ ëª©ë¡ ì¶œë ¥
  python start_inference.py --model ./outputs/checkpoint-12000   # íŠ¹ì • ëª¨ë¸ ì‹¤í–‰
  python start_inference.py --model /path/to/model --device cpu  # CPUë¡œ ì‹¤í–‰
  python start_inference.py --list                              # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡
        """
    )
    
    parser.add_argument(
        "--model", "-m",
        type=str,
        help="ëª¨ë¸ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ"
    )
    
    parser.add_argument(
        "--device", "-d",
        type=str,
        default="auto",
        choices=["auto", "cpu", "cuda"],
        help="ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (ê¸°ë³¸ê°’: auto)"
    )
    
    parser.add_argument(
        "--tokenizer", "-t",
        type=str,
        help="í† í¬ë‚˜ì´ì € íŒŒì¼ ê²½ë¡œ (ì„ íƒì )"
    )
    
    parser.add_argument(
        "--list", "-l",
        action="store_true",
        help="ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ë§Œ ì¶œë ¥"
    )
    
    parser.add_argument(
        "--test",
        action="store_true",
        help="ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰"
    )
    
    args = parser.parse_args()
    
    # í—¤ë” ì¶œë ¥
    print("=" * 70)
    print("ğŸ‡°ğŸ‡· í•œêµ­ì–´ ì†Œí˜• ì–¸ì–´ëª¨ë¸ (Korean SLLM) ì¶”ë¡  ì‹œìŠ¤í…œ")
    print("=" * 70)
    print()
    
    # ëª©ë¡ ì¶œë ¥ ëª¨ë“œ
    if args.list:
        list_available_models()
        return
    
    # ëª¨ë¸ ê²½ë¡œê°€ ì§€ì •ë˜ì§€ ì•Šì€ ê²½ìš°
    if not args.model:
        print("â„¹ï¸  ëª¨ë¸ ë””ë ‰í† ë¦¬ê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print()
        
        if list_available_models():
            print()
            print("ìœ„ ëª©ë¡ì—ì„œ ëª¨ë¸ì„ ì„ íƒí•˜ë ¤ë©´:")
            print("  python start_inference.py --model <ê²½ë¡œ>")
        
        return
    
    # ëª¨ë¸ ë””ë ‰í† ë¦¬ ê²€ì¦
    if not validate_model_directory(args.model):
        print()
        print("ğŸ’¡ ë„ì›€ë§:")
        print("  â€¢ ëª¨ë¸ ë””ë ‰í† ë¦¬ì—ëŠ” pytorch_model.binê³¼ config.jsonì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤")
        print("  â€¢ --list ì˜µì…˜ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        sys.exit(1)
    
    # í•´ì„ëœ ê²½ë¡œ ì‚¬ìš©
    resolved_model_path = resolve_model_path(args.model)
    print(f"ğŸ–¥ï¸  ë””ë°”ì´ìŠ¤: {args.device}")
    if args.tokenizer:
        print(f"ğŸ“ í† í¬ë‚˜ì´ì €: {args.tokenizer}")
    print()
    
    # ì‹¤ì œ ì¶”ë¡  ì‹¤í–‰
    try:
        # í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€í•˜ì—¬ ëª¨ë“ˆ import ê°€ëŠ¥í•˜ê²Œ í•¨
        current_dir = os.path.dirname(os.path.abspath(__file__))
        if current_dir not in sys.path:
            sys.path.insert(0, current_dir)
        
        from run_inference import main as run_main
        
        # sys.argv ìˆ˜ì •í•˜ì—¬ run_inferenceì— ì „ë‹¬ (í•´ì„ëœ ê²½ë¡œ ì‚¬ìš©)
        sys.argv = ["run_inference.py", "--checkpoint", resolved_model_path, "--device", args.device]
        
        if args.tokenizer:
            sys.argv.extend(["--tokenizer", args.tokenizer])
        
        if args.test:
            sys.argv.append("--test")
        
        # ë°°ë„ˆ ìˆ¨ê¸°ê¸° (ì´ë¯¸ ì¶œë ¥í–ˆìœ¼ë¯€ë¡œ)
        sys.argv.append("--no-banner")
        
        print("ğŸš€ ì¶”ë¡  ì‹œìŠ¤í…œì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        print()
        
        run_main()
        
    except ImportError as e:
        print(f"âŒ ëª¨ë“ˆ ì„í¬íŠ¸ ì˜¤ë¥˜: {e}")
        print("í•„ìˆ˜ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:")
        print("  pip install -r requirements.txt")
        sys.exit(1)
    
    except KeyboardInterrupt:
        print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main() 