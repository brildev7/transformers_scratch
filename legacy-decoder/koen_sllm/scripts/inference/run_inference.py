#!/usr/bin/env python3
"""
í•œêµ­ì–´ ì†Œí˜• ì–¸ì–´ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ì¶”ë¡  ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

import sys
import os
import argparse
from pathlib import Path

# ì ˆëŒ€ ê²½ë¡œë¡œ ëª¨ë“ˆ ì„í¬íŠ¸ (í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€)
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))
from console_app import main as console_main


def print_banner():
    """í”„ë¡œê·¸ë¨ ì‹œì‘ ë°°ë„ˆ ì¶œë ¥"""
    print("=" * 70)
    print("ğŸ‡°ğŸ‡· í•œêµ­ì–´ ì†Œí˜• ì–¸ì–´ëª¨ë¸ (Korean SLLM) ì¶”ë¡  ì‹œìŠ¤í…œ")
    print("=" * 70)
    print()


def check_requirements():
    """í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤ì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
    try:
        import torch
        import numpy
        print(f"âœ… PyTorch {torch.__version__} ì„¤ì¹˜ë¨")
        print(f"âœ… CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"   GPU ì¥ì¹˜: {torch.cuda.get_device_name()}")
            print(f"   GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
        print()
    except ImportError as e:
        print(f"âŒ í•„ìˆ˜ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print("pip install -r requirements.txt")
        sys.exit(1)


def find_available_checkpoints(base_path="./outputs"):
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì²´í¬í¬ì¸íŠ¸ ëª©ë¡ ë°˜í™˜"""
    checkpoints = []
    
    if os.path.exists(base_path):
        for item in os.listdir(base_path):
            checkpoint_path = os.path.join(base_path, item)
            if (os.path.isdir(checkpoint_path) and 
                item.startswith("checkpoint-") and
                os.path.exists(os.path.join(checkpoint_path, "pytorch_model.bin")) and
                os.path.exists(os.path.join(checkpoint_path, "config.json"))):
                checkpoints.append(checkpoint_path)
    
    return sorted(checkpoints)


def select_checkpoint_interactive():
    """ëŒ€í™”í˜•ìœ¼ë¡œ ì²´í¬í¬ì¸íŠ¸ ì„ íƒ"""
    checkpoints = find_available_checkpoints()
    
    if not checkpoints:
        print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("./outputs/ ë””ë ‰í† ë¦¬ì— ì²´í¬í¬ì¸íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        sys.exit(1)
    
    print("ğŸ“ ì‚¬ìš© ê°€ëŠ¥í•œ ì²´í¬í¬ì¸íŠ¸:")
    for i, checkpoint in enumerate(checkpoints, 1):
        # íŒŒì¼ í¬ê¸° ì •ë³´
        model_file = os.path.join(checkpoint, "pytorch_model.bin")
        if os.path.exists(model_file):
            size_gb = os.path.getsize(model_file) / (1024**3)
            print(f"  {i}. {checkpoint} ({size_gb:.1f} GB)")
        else:
            print(f"  {i}. {checkpoint}")
    
    print()
    
    while True:
        try:
            choice = input(f"ì²´í¬í¬ì¸íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (1-{len(checkpoints)}): ").strip()
            
            if not choice:
                # ì—”í„°ë§Œ ëˆ„ë¥´ë©´ ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ì„ íƒ
                return checkpoints[-1]
            
            idx = int(choice) - 1
            if 0 <= idx < len(checkpoints):
                return checkpoints[idx]
            else:
                print(f"âŒ 1ê³¼ {len(checkpoints)} ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        except ValueError:
            print("âŒ ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        except KeyboardInterrupt:
            print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            sys.exit(0)


def quick_test(checkpoint_path, device="auto"):
    """ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸ§ª ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
    
    try:
        from inference import InferenceEngine
        
        # ëª¨ë¸ ë¡œë“œ
        engine = InferenceEngine.from_checkpoint(checkpoint_path, device=device)
        
        # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
        test_prompts = ["ì•ˆë…•í•˜ì„¸ìš”", "ì˜¤ëŠ˜ ë‚ ì”¨ëŠ”", "ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜"]
        
        for prompt in test_prompts:
            print(f"\ní”„ë¡¬í”„íŠ¸: '{prompt}'")
            response = engine.generate_text(
                prompt=prompt,
                max_length=30,
                temperature=0.8,
                do_sample=True
            )
            print(f"ì‘ë‹µ: '{response}'")
        
        print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
        return True
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="í•œêµ­ì–´ ì†Œí˜• ì–¸ì–´ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python run_inference.py                                    # ëŒ€í™”í˜• ì²´í¬í¬ì¸íŠ¸ ì„ íƒ
  python run_inference.py --checkpoint ./outputs/checkpoint-12000
  python run_inference.py --test --checkpoint ./outputs/checkpoint-8000
  python run_inference.py --device cpu
        """
    )
    
    parser.add_argument(
        "--checkpoint",
        type=str,
        default=None,
        help="ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ëŒ€í™”í˜• ì„ íƒ)"
    )
    
    parser.add_argument(
        "--tokenizer",
        type=str,
        default=None,
        help="í† í¬ë‚˜ì´ì € ì–´íœ˜ íŒŒì¼ ê²½ë¡œ (ì„ íƒì )"
    )
    
    parser.add_argument(
        "--device",
        type=str,
        default="auto",
        choices=["auto", "cpu", "cuda"],
        help="ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤"
    )
    
    parser.add_argument(
        "--test",
        action="store_true",
        help="ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰í•˜ê³  ì¢…ë£Œ"
    )
    
    parser.add_argument(
        "--no-banner",
        action="store_true",
        help="ì‹œì‘ ë°°ë„ˆ ìˆ¨ê¸°ê¸°"
    )
    
    args = parser.parse_args()
    
    # ë°°ë„ˆ ì¶œë ¥
    if not args.no_banner:
        print_banner()
    
    # ìš”êµ¬ì‚¬í•­ ì²´í¬
    check_requirements()
    
    # ì²´í¬í¬ì¸íŠ¸ ì„ íƒ
    if args.checkpoint:
        checkpoint_path = args.checkpoint
        
        # ì²´í¬í¬ì¸íŠ¸ ìœ íš¨ì„± ê²€ì‚¬
        if not os.path.exists(checkpoint_path):
            print(f"âŒ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}")
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì²´í¬í¬ì¸íŠ¸ ì œì•ˆ
            available = find_available_checkpoints()
            if available:
                print("\nì‚¬ìš© ê°€ëŠ¥í•œ ì²´í¬í¬ì¸íŠ¸:")
                for cp in available:
                    print(f"  â€¢ {cp}")
            
            sys.exit(1)
        
        # í•„ìˆ˜ íŒŒì¼ í™•ì¸
        model_file = os.path.join(checkpoint_path, "pytorch_model.bin")
        config_file = os.path.join(checkpoint_path, "config.json")
        
        if not os.path.exists(model_file):
            print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_file}")
            sys.exit(1)
        
        if not os.path.exists(config_file):
            print(f"âŒ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_file}")
            sys.exit(1)
    
    else:
        # ëŒ€í™”í˜• ì²´í¬í¬ì¸íŠ¸ ì„ íƒ
        checkpoint_path = select_checkpoint_interactive()
    
    print(f"ğŸ“‚ ì„ íƒëœ ì²´í¬í¬ì¸íŠ¸: {checkpoint_path}")
    
    # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
    if args.test:
        success = quick_test(checkpoint_path, args.device)
        sys.exit(0 if success else 1)
    
    # ì½˜ì†” ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
    print("\nğŸš€ ëŒ€í™”í˜• ì½˜ì†”ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("(ì¢…ë£Œí•˜ë ¤ë©´ /exit ë˜ëŠ” Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”)")
    print()
    
    # sys.argv ìˆ˜ì •í•˜ì—¬ console_appì— ì „ë‹¬
    sys.argv = [
        "console_app.py",
        "--checkpoint", checkpoint_path,
        "--device", args.device
    ]
    
    # ê°œì„ ëœ í† í¬ë‚˜ì´ì €ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©
    if not args.tokenizer:
        sys.argv.extend(["--use-improved-tokenizer"])
    
    sys.argv.extend([
        sys.argv.extend(["--tokenizer", args.tokenizer])
    
    try:
        console_main()
    except KeyboardInterrupt:
        print("\ní”„ë¡œê·¸ë¨ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 