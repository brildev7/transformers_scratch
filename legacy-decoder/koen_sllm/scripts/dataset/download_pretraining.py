#!/usr/bin/env python3
"""
Pretraining Dataset Download Script
ì‚¬ì „í›ˆë ¨ìš© ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ (configs/dataset/pretraining.json ê¸°ë°˜)
"""
import sys
import json
import argparse
import logging
from pathlib import Path

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬
script_dir = Path(__file__).parent
sys.path.insert(0, str(script_dir))

from dataset_loader import DynamicDatasetLoader

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class PretrainingDatasetDownloader:
    """ì‚¬ì „í›ˆë ¨ìš© ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë” (configs/dataset ê¸°ë°˜)"""
    
    def __init__(self, config_path: str = None, use_unique_names: bool = False):
        if config_path is None:
            config_path = script_dir.parent.parent / "configs" / "dataset" / "pretraining.json"
        
        self.config_path = Path(config_path)
        self.config = self._load_config()
        self.use_unique_names = use_unique_names
        
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê³„ì‚°
        self.project_root = script_dir.parent.parent.parent.parent
        self.output_dir = self.project_root / "datasets"
        self.cache_dir = self.project_root / "models"
        
        logger.info(f"ğŸ“‹ ì„¤ì • íŒŒì¼: {self.config_path}")
        logger.info(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {self.output_dir}")
        logger.info(f"ğŸ’¾ ìºì‹œ ë””ë ‰í† ë¦¬: {self.cache_dir}")
        if self.use_unique_names:
            logger.info(f"ğŸ“ ê³ ìœ í•œ íŒŒì¼ëª… ì‚¬ìš©: í™œì„±í™”")
        
    def _load_config(self):
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        if not self.config_path.exists():
            raise FileNotFoundError(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.config_path}")
        
        with open(self.config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _resolve_dataset_config_path(self, relative_path: str) -> Path:
        """ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜"""
        base_dir = self.config_path.parent
        return (base_dir / relative_path).resolve()
    
    def get_dataset_info(self):
        """ë°ì´í„°ì…‹ ì •ë³´ í‘œì‹œ"""
        logger.info(f"ğŸ“Š ì‚¬ì „í›ˆë ¨ ë°ì´í„°ì…‹ ì„¤ì •:")
        logger.info(f"   ì„¤ëª…: {self.config.get('description', 'N/A')}")
        
        # í•œêµ­ì–´ ë°ì´í„°ì…‹ ì •ë³´
        if 'korean_config' in self.config:
            korean_config_path = self._resolve_dataset_config_path(self.config['korean_config'])
            if korean_config_path.exists():
                logger.info(f"\nğŸ‡°ğŸ‡· í•œêµ­ì–´ ë°ì´í„°ì…‹:")
                korean_loader = DynamicDatasetLoader(str(korean_config_path), str(self.cache_dir))
                korean_info = korean_loader.get_dataset_info()
                for i, ds in enumerate(korean_info['enabled_datasets'], 1):
                    logger.info(f"   {i}. {ds['description']}")
            else:
                logger.warning(f"âŒ í•œêµ­ì–´ ì„¤ì • íŒŒì¼ ì—†ìŒ: {korean_config_path}")
        
        # ì˜ì–´ ë°ì´í„°ì…‹ ì •ë³´
        if 'english_config' in self.config:
            english_config_path = self._resolve_dataset_config_path(self.config['english_config'])
            if english_config_path.exists():
                logger.info(f"\nğŸ‡ºğŸ‡¸ ì˜ì–´ ë°ì´í„°ì…‹:")
                english_loader = DynamicDatasetLoader(str(english_config_path), str(self.cache_dir))
                english_info = english_loader.get_dataset_info()
                for i, ds in enumerate(english_info['enabled_datasets'], 1):
                    logger.info(f"   {i}. {ds['description']}")
            else:
                logger.warning(f"âŒ ì˜ì–´ ì„¤ì • íŒŒì¼ ì—†ìŒ: {english_config_path}")
        
        # í˜¼í•© ë¹„ìœ¨ ì •ë³´
        if 'mixing_ratio' in self.config:
            logger.info(f"\nâš–ï¸  ì–¸ì–´ë³„ í˜¼í•© ë¹„ìœ¨:")
            for lang, ratio in self.config['mixing_ratio'].items():
                logger.info(f"   {lang}: {ratio*100:.1f}%")
    
    def download_datasets(self, small_mode: bool = False, force: bool = False):
        """ì‚¬ì „í›ˆë ¨ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ"""
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        korean_data = []
        english_data = []
        
        # í•œêµ­ì–´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        if 'korean_config' in self.config:
            korean_config_path = self._resolve_dataset_config_path(self.config['korean_config'])
            if korean_config_path.exists():
                logger.info("ğŸ‡°ğŸ‡· í•œêµ­ì–´ ì‚¬ì „í›ˆë ¨ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘...")
                
                korean_loader = DynamicDatasetLoader(str(korean_config_path), str(self.cache_dir))
                korean_output_file = self.output_dir / "korean_pretraining_corpus.json"
                
                if korean_output_file.exists() and not force:
                    logger.info(f"ê¸°ì¡´ í•œêµ­ì–´ ë°ì´í„° ì‚¬ìš©: {korean_output_file}")
                else:
                    if force and korean_output_file.exists():
                        korean_output_file.unlink()
                        logger.info("ê¸°ì¡´ í•œêµ­ì–´ ë°ì´í„° ì‚­ì œ")
                    
                    korean_data = korean_loader.load_all_datasets(small_mode=small_mode)
                    if korean_data:
                        korean_loader.save_texts(korean_data, str(korean_output_file))
            else:
                logger.warning(f"í•œêµ­ì–´ ì„¤ì • íŒŒì¼ ì—†ìŒ: {korean_config_path}")
        
        # ì˜ì–´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        if 'english_config' in self.config:
            english_config_path = self._resolve_dataset_config_path(self.config['english_config'])
            if english_config_path.exists():
                logger.info("ğŸ‡ºğŸ‡¸ ì˜ì–´ ì‚¬ì „í›ˆë ¨ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘...")
                
                english_loader = DynamicDatasetLoader(str(english_config_path), str(self.cache_dir))
                english_output_file = self.output_dir / "english_pretraining_corpus.json"
                
                if english_output_file.exists() and not force:
                    logger.info(f"ê¸°ì¡´ ì˜ì–´ ë°ì´í„° ì‚¬ìš©: {english_output_file}")
                else:
                    if force and english_output_file.exists():
                        english_output_file.unlink()
                        logger.info("ê¸°ì¡´ ì˜ì–´ ë°ì´í„° ì‚­ì œ")
                    
                    english_data = english_loader.load_all_datasets(small_mode=small_mode)
                    if english_data:
                        english_loader.save_texts(english_data, str(english_output_file))
            else:
                logger.warning(f"ì˜ì–´ ì„¤ì • íŒŒì¼ ì—†ìŒ: {english_config_path}")
        
        # í˜¼í•© ë°ì´í„°ì…‹ ìƒì„±
        if korean_data or english_data:
            self._create_mixed_dataset(korean_data, english_data, small_mode)
        
        return korean_data, english_data
    
    def _create_mixed_dataset(self, korean_data, english_data, small_mode):
        """í˜¼í•© ë°ì´í„°ì…‹ ìƒì„±"""
        logger.info("ğŸ”€ í˜¼í•© ì‚¬ì „í›ˆë ¨ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
        
        mixing_ratio = self.config.get('mixing_ratio', {'korean': 0.3, 'english': 0.7})
        korean_ratio = mixing_ratio.get('korean', 0.3)
        english_ratio = mixing_ratio.get('english', 0.7)
        
        mixed_data = []
        
        # í•œêµ­ì–´ ë°ì´í„° ì¶”ê°€
        if korean_data:
            korean_count = int(len(korean_data) * korean_ratio / (korean_ratio + english_ratio))
            mixed_data.extend(korean_data[:korean_count])
            logger.info(f"   í•œêµ­ì–´: {korean_count:,}ê°œ ë¬¸ì„œ ({korean_ratio*100:.1f}%)")
        
        # ì˜ì–´ ë°ì´í„° ì¶”ê°€
        if english_data:
            english_count = int(len(english_data) * english_ratio / (korean_ratio + english_ratio))
            mixed_data.extend(english_data[:english_count])
            logger.info(f"   ì˜ì–´: {english_count:,}ê°œ ë¬¸ì„œ ({english_ratio*100:.1f}%)")
        
        # ë°ì´í„° ì„ê¸°
        import random
        random.shuffle(mixed_data)
        
        # ì €ì¥
        suffix = "_small" if small_mode else ""
        mixed_output_file = self.output_dir / f"mixed_pretraining_corpus{suffix}.json"
        
        with open(mixed_output_file, 'w', encoding='utf-8') as f:
            json.dump(mixed_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ¯ í˜¼í•© ë°ì´í„°ì…‹ ì €ì¥: {mixed_output_file}")
        logger.info(f"   ì´ ë¬¸ì„œ ìˆ˜: {len(mixed_data):,}ê°œ")


def main():
    parser = argparse.ArgumentParser(description="ì‚¬ì „í›ˆë ¨ìš© ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ (configs/dataset ê¸°ë°˜)")
    parser.add_argument("--config", type=str, help="ì„¤ì • íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸: configs/dataset/pretraining.json)")
    parser.add_argument("--info", action="store_true", help="ë°ì´í„°ì…‹ ì •ë³´ë§Œ í‘œì‹œ")
    parser.add_argument("--small", action="store_true", help="ì†ŒëŸ‰ ìƒ˜í”Œë§Œ ë‹¤ìš´ë¡œë“œ")
    parser.add_argument("--force", action="store_true", help="ê¸°ì¡´ ë°ì´í„° ë¬´ì‹œí•˜ê³  ìƒˆë¡œ ë‹¤ìš´ë¡œë“œ")
    parser.add_argument("--korean_only", action="store_true", help="í•œêµ­ì–´ë§Œ ë‹¤ìš´ë¡œë“œ")
    parser.add_argument("--english_only", action="store_true", help="ì˜ì–´ë§Œ ë‹¤ìš´ë¡œë“œ")
    parser.add_argument("--unique_names", action="store_true", help="ê³ ìœ í•œ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥")
    
    args = parser.parse_args()
    
    try:
        downloader = PretrainingDatasetDownloader(args.config)
        
        if args.info:
            downloader.get_dataset_info()
            return 0
        
        # ì–¸ì–´ë³„ ë‹¤ìš´ë¡œë“œ ì˜µì…˜ ì²˜ë¦¬
        if args.korean_only:
            # í•œêµ­ì–´ë§Œ ë‹¤ìš´ë¡œë“œí•˜ë„ë¡ ì„¤ì • ì„ì‹œ ìˆ˜ì •
            downloader.config = {k: v for k, v in downloader.config.items() if k != 'english_config'}
        elif args.english_only:
            # ì˜ì–´ë§Œ ë‹¤ìš´ë¡œë“œí•˜ë„ë¡ ì„¤ì • ì„ì‹œ ìˆ˜ì •
            downloader.config = {k: v for k, v in downloader.config.items() if k != 'korean_config'}
        
        korean_data, english_data = downloader.download_datasets(
            small_mode=args.small,
            force=args.force
        )
        
        logger.info("\nğŸ‰ ì‚¬ì „í›ˆë ¨ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        logger.info(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {downloader.output_dir}")
        if korean_data:
            logger.info(f"ğŸ‡°ğŸ‡· í•œêµ­ì–´: {len(korean_data):,}ê°œ ë¬¸ì„œ")
        if english_data:
            logger.info(f"ğŸ‡ºğŸ‡¸ ì˜ì–´: {len(english_data):,}ê°œ ë¬¸ì„œ")
        
        return 0
        
    except Exception as e:
        logger.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 1


if __name__ == "__main__":
    exit(main()) 